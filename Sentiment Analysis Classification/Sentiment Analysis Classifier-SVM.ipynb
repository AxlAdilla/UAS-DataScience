{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e167c8a",
   "metadata": {},
   "source": [
    "Axl Adilla <br>\n",
    "20/466397/PPA/05963\n",
    "\n",
    "UAS Data Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "250bc3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96cea870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentimen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saya juga mau vouchee @gojekindonesia  https:/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>download gojek duluuu uwuwu</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aminnn...#orderan goride mhn di lancar kan.all...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tq @gojekindonesia @golifeindonesia üñ§. Harusny...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Semoga Twitter panjang umur. Berkomunikasi den...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sentimen\n",
       "0  Saya juga mau vouchee @gojekindonesia  https:/...         1\n",
       "1                        download gojek duluuu uwuwu         1\n",
       "2  Aminnn...#orderan goride mhn di lancar kan.all...         1\n",
       "3  Tq @gojekindonesia @golifeindonesia üñ§. Harusny...         1\n",
       "4  Semoga Twitter panjang umur. Berkomunikasi den...         1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('gojek_twitter_dataset.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44892e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3062\n",
       "1     938\n",
       "Name: sentimen, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['sentimen'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58a14901",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_class_0 = dataset[dataset['sentimen'] == 0]\n",
    "dataset_class_1 = dataset[dataset['sentimen'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae11d195",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_class_1_over = dataset_class_1.sample(3062, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e39104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_class_0_under = dataset_class_0.sample(938, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50478060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3062\n",
       "1    3062\n",
       "Name: sentimen, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.concat([dataset_class_0, dataset_class_1_over], axis=0)\n",
    "dataset['sentimen'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57518e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_y = dataset['sentimen'].copy().values\n",
    "dataset_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "413c8794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iyaa min akur dong :((( biar saldoku tida terpisah bagaikan adam dan hawa waktu itu :‚Äù‚Äù',\n",
       "       \"hayu tolong dibantuin! \\n@gojekindonesia\\n@gojek24jam\\n@infodepok_id\\n@CCICPolri \\nuntung mba nya nyalain data hp, jd bisa di lacak:') https://twitter.com/yuniarayutyas/status/1167387194496962560\\xa0‚Ä¶\",\n",
       "       'sengaja banget nih orang... \\nsumpah nyeaeeek banget gue.... \\nsalah gak salah driver ttp nanggung deritanya  \\n\\n@gojekindonesia  pic.twitter.com/T9mmC1AlBD',\n",
       "       ...,\n",
       "       '@gojekindonesia kalo salah ngasi bintang ke driver karna ke pencet sama anak kecil bisa diganti ga ya? kasian soalnya kepencetnya ratingnya kecil takut berdampak negatif ke drivernya',\n",
       "       'Pada akhirnya barusan GoFood mas hahahaha üòÇ',\n",
       "       '@gojekindonesia kalo salah ngasi bintang ke driver karna ke pencet sama anak kecil bisa diganti ga ya? kasian soalnya kepencetnya ratingnya kecil takut berdampak negatif ke drivernya'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_x = dataset['tweet'].copy().values\n",
    "dataset_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a65972c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_link(text):\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\S*.com\\S*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'@\\S*\\s', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\S*#\\S*', '', text, flags=re.MULTILINE)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "071c6940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_number_symbol(text):\n",
    "    text = re.sub(r'\\d.', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.MULTILINE)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "171bfde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "def remove_emoji(text):\n",
    "    text = emoji.get_emoji_regexp().sub(\"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9809928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "def remove_stopwords(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    listStopword =  set(stopwords.words('indonesian'))\n",
    "\n",
    "    removed = []\n",
    "    for t in tokens:\n",
    "        if t not in listStopword:\n",
    "            removed.append(t)\n",
    "    return \" \".join(removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca38cbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "sastrawi_factory = StemmerFactory()\n",
    "sastrawi_stemmer = sastrawi_factory.create_stemmer()\n",
    "def stemming(text):\n",
    "    text = sastrawi_stemmer.stem(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9703d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(text):\n",
    "    text = remove_link(text)\n",
    "    text = remove_emoji(text)\n",
    "    text = remove_number_symbol(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = stemming(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d657dd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset_x, dataset_y, random_state=1, test_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1fcf213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector(fasttext_model, text):\n",
    "    text = preprocessing_data(text)\n",
    "    return fasttext_model.get_sentence_vector(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86afdc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "fasttext_model = fasttext.load_model(\"cc.id.100.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d26b6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_vector = [ create_vector(fasttext_model, x)  for x in x_test]\n",
    "x_train_vector = [ create_vector(fasttext_model, x)  for x in x_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c2f185c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score,cross_validate\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(x_train_vector,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4faf5664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.72      0.69      2147\n",
      "           1       0.69      0.63      0.66      2140\n",
      "\n",
      "    accuracy                           0.68      4287\n",
      "   macro avg       0.68      0.68      0.68      4287\n",
      "weighted avg       0.68      0.68      0.68      4287\n",
      "\n",
      "[[1549  598]\n",
      " [ 784 1356]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "y_pred = clf.predict(x_test_vector)\n",
    "\n",
    "classif_report = classification_report(y_test, y_pred)\n",
    "confus_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(classif_report)\n",
    "print(confus_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02530f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.82      0.77       915\n",
      "           1       0.80      0.69      0.74       922\n",
      "\n",
      "    accuracy                           0.76      1837\n",
      "   macro avg       0.76      0.76      0.76      1837\n",
      "weighted avg       0.76      0.76      0.76      1837\n",
      "\n",
      "[[752 163]\n",
      " [283 639]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(x_train_vector)\n",
    "\n",
    "classif_report = classification_report(y_train, y_pred)\n",
    "confus_matrix = confusion_matrix(y_train, y_pred)\n",
    "\n",
    "print(classif_report)\n",
    "print(confus_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
